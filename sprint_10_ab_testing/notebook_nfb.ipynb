{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online store A/B test\n",
    "We've got some hypotheses meant to boost revenue that need to be prioritised, then we'll do an A/B test and obviously that'll be analysed. That's it.\n",
    "\n",
    "We'll have three tables to work with:\n",
    "* hypotheses_us.csv, the hypotheses along with some scores for calculation of RICE and ICE\n",
    "* orders_us.csv, the orders during the A/B test, with who made them on what day, which group they were part of, and how much they spent\n",
    "* visits_us.csv, how many visits were assigned to each group on each day of the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats as st\n",
    "import seaborn as sns\n",
    "\n",
    "hypo = pd.read_csv(\"datasets/hypotheses_us.csv\", sep=\";\")\n",
    "orders = pd.read_csv(\"datasets/orders_us.csv\", dtype={\"group\": \"category\"}, parse_dates=[\"date\"])\n",
    "visits = pd.read_csv(\"datasets/visits_us.csv\", dtype={\"group\": \"category\"}, parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Looking at the tables and checking for weird stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title case column names, how annoying. Other than that, looks fine. Also, I want to see what these proposals actually are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "hypo[\"Hypothesis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.info()\n",
    "orders.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Id\". That's annoying too.\n",
    "\n",
    "Revenue has one decimal place. Not zero and not two. Not really a problem, but kind of weird. I guess everything was just a multiple of ten cents. Or pence, or kopeyki.\n",
    "\n",
    "What is a problem is that this is about the whole of August 2019 and we'll be doing some cumulative stats, and here we are starting in the middle, so let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = orders.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits.info()\n",
    "visits.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fine.\n",
    "\n",
    "Now let's rename these columns or I'll definitely type them wrong a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo = hypo.rename(str.lower, axis=1)\n",
    "orders = orders.rename(columns={\"transactionId\": \"transaction_id\", \"visitorId\": \"visitor_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orders[\"transaction_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orders[orders[\"revenue\"] <= 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = orders.groupby(\"visitor_id\").agg({\"group\": \"nunique\"})\n",
    "print(test[test[\"group\"] != 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems like a lot. How many visitors total do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orders[\"visitor_id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((test[test[\"group\"] != 1][\"group\"].count()) / 1031)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 5% of visitors being in both groups. We'll... just ignore those guys. At least ignore their orders. It'd be nice if the visits table was actually a table with each visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgnums = orders.groupby(\"visitor_id\", as_index=False).agg({\"group\": \"nunique\"})\n",
    "dualgrouped = vgnums[vgnums[\"group\"] != 1][\"visitor_id\"]\n",
    "orders = orders[~orders[\"visitor_id\"].isin(dualgrouped)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Ranking the hypotheses\n",
    "For this we'll use methods called ICE and RICE. RICE stands for Reach, Impact, Confidence, Effort and ICE is simply RICE without reach.\n",
    "\n",
    "ICE is (Impact * Confidence) / Effort. That is, we rate an idea for the impact it would have if it worked well, how likely it is to work well, and how much time, resource, and cleverness it would take to implement. For example, a hypothetical feature would almost definitely have a decent impact if we added it, but actually building it would be rather impractical, so its good impact and great confidence would be divided by the high effort score and leave it with a middling overall score. RICE simply adds reach to the multiplication, representing what fraction of the users it would be expected to affect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo[\"ice\"] = hypo[\"impact\"] * hypo[\"confidence\"] / hypo[\"effort\"]\n",
    "hypo[\"rice\"] = hypo[\"reach\"] * hypo[\"impact\"] * hypo[\"confidence\"] / hypo[\"effort\"]\n",
    "coldsort = hypo.sort_values(by=\"ice\", ascending=False)\n",
    "tastysort = hypo.sort_values(by=\"rice\", ascending=False)\n",
    "display(coldsort)\n",
    "display(tastysort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The birthday promotion wins on ICE, but the fact that it'll only exist for a certain user 1/365th of the time (or a quarter as often for the Feb 29ers out there) knocks it down in RICE. The big winners in RICE compared to ICE are the recommendation blocks, which jumps three places because of course most people are going to see that, and making the subscription form be more prominent or perhaps exist at all, which gets first place because everyone will see that, though it was so good anyway that even a middling reach would've brought it victory. We could speculate about how many people will actually use these things when they see them, but the scoring isn't part of our job.\n",
    "\n",
    "We could also do it visually. Here's a scatterplot of the ICEs versus the RICEs. Note the practically reachless birthday idea way in the upper left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hypo, x=\"rice\", y=\"ice\", hover_data=[\"hypothesis\", \"ice\", \"rice\"])\n",
    "fig.update_layout(xaxis_title=\"RICE\", yaxis_title=\"ICE\", title=\"Subscription form wins by a long way\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a pair plot too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(hypo, x_vars=[\"reach\", \"impact\", \"confidence\", \"effort\"], y_vars=[\"reach\", \"impact\", \"confidence\", \"effort\"], corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the effort row, that lower right corner is where you want to be, a high effect (or confidence of having one) with low effort. That sounds like it'd be a tradeoff, and of course it is, but some simple but effective (at least effective-sounding) ideas manage to do well. Also, note the lack of ideas that are both high-impact and either low-confidence or high-effort, no \"big risk, big reward\" things. Which is fine, we wouldn't be too interested in them anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: A/B test analysis\n",
    "We did the A/B test! You didn't get to see it and neither did I, but as you can see from the existence of the group columns in the other tables, it happened. So I kind of did things in backwards time. Anyway, let's analyse it.\n",
    "\n",
    "First of all, cumulative revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_revenues = orders.groupby([\"date\", \"group\"], as_index=False).agg({\"revenue\": \"sum\"})\n",
    "\n",
    "day_revenues[\"revenue_cum\"] = day_revenues.groupby(\"group\").cumsum()\n",
    "fig = px.line(day_revenues, x=\"date\", y=\"revenue_cum\", color=\"group\")\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Cumulative revenue\", legend_title_text=\"Group\", title='Group B \"wins\" on an outlier')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group B had one really good day, but other than that it was quite even. Though even not counting the big day, group B was slightly better.\n",
    "\n",
    "Next up, average order size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders[\"cumsum\"] = orders.groupby(\"group\")[\"revenue\"].cumsum()\n",
    "orders[\"cumcount\"] = orders.groupby(\"group\")[\"revenue\"].cumcount() + 1\n",
    "orders[\"cumavg\"] = orders[\"cumsum\"] / orders[\"cumcount\"]\n",
    "day_end_stats = orders.drop_duplicates(subset=[\"date\", \"group\"], keep=\"last\")\n",
    "del day_end_stats[\"transaction_id\"]\n",
    "del day_end_stats[\"visitor_id\"]\n",
    "del day_end_stats[\"revenue\"]\n",
    "\n",
    "fig = px.line(day_end_stats, x=\"date\", y=\"cumavg\", color=\"group\")\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Cumulative average order size\", legend_title_text=\"Group\", title='Group B \"wins\" on the same outlier')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You think we should have a look at the distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Histogram(name=\"Group A\", x=orders[orders[\"group\"] == \"A\"][\"revenue\"]),\n",
    "    go.Histogram(name=\"Group B\", x=orders[orders[\"group\"] == \"B\"][\"revenue\"])\n",
    "])\n",
    "fig.update_layout(xaxis_title=\"Revenue\", yaxis_title=\"Number of orders\", title=\"This is why you don't always trust plain means\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, that's about what I expected. Let's zoom in on the ones less than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Histogram(name=\"Group A\", x=orders[(orders[\"group\"] == \"A\") & (orders[\"revenue\"] < 1000)][\"revenue\"]),\n",
    "    go.Histogram(name=\"Group B\", x=orders[(orders[\"group\"] == \"B\") & (orders[\"revenue\"] < 1000)][\"revenue\"])\n",
    "])\n",
    "fig.update_layout(xaxis_title=\"Revenue\", yaxis_title=\"Number of orders\", title=\"This is why you don't always trust plain means\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also get some actual percentile cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders[\"revenue\"].describe(percentiles=[.05, .10, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "300 seems like the best decimally round number to cut it at. From here on, orders of 300 or more will count as being 300. The meaningfulness of the test depends on it.\n",
    "\n",
    "### Let's try this again\n",
    "#### Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_orig = orders.copy()\n",
    "orders[\"revenue\"] = orders[\"revenue\"].where(orders[\"revenue\"] <= 300, 300)\n",
    "\n",
    "day_revenues = orders.groupby([\"date\", \"group\"], as_index=False).agg({\"revenue\": \"sum\"})\n",
    "\n",
    "day_revenues[\"revenue_cum\"] = day_revenues.groupby(\"group\").cumsum()\n",
    "fig = px.line(day_revenues, x=\"date\", y=\"revenue_cum\", color=\"group\")\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Cumulative revenue\", legend_title_text=\"Group\", title=\"Group B has brought 13% more revenue\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_grouped = visits.groupby(\"group\").agg({\"visits\": \"sum\"})\n",
    "v_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group B has brought in 13% more money with only 1% more visits. Very nice. But as important as simple revenue is, we've got more metrics than that. Here's average order size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders[\"cumsum\"] = orders.groupby(\"group\")[\"revenue\"].cumsum()\n",
    "orders[\"cumcount\"] = orders.groupby(\"group\")[\"revenue\"].cumcount() + 1\n",
    "orders[\"cumavg\"] = orders[\"cumsum\"] / orders[\"cumcount\"]\n",
    "day_end_stats = orders.drop_duplicates(subset=[\"date\", \"group\"], keep=\"last\")\n",
    "del day_end_stats[\"transaction_id\"]\n",
    "del day_end_stats[\"visitor_id\"]\n",
    "del day_end_stats[\"revenue\"]\n",
    "\n",
    "fig = px.line(day_end_stats, x=\"date\", y=\"cumavg\", color=\"group\")\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Running average order size\", legend_title_text=\"Group\", title=\"Mean order size: the last lead change was a few days ago\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in relative terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_a = day_end_stats[day_end_stats[\"group\"] == \"A\"]\n",
    "group_b = day_end_stats[day_end_stats[\"group\"] == \"B\"]\n",
    "merge = group_a.merge(group_b, how=\"left\", on=\"date\", suffixes=[\"_a\", \"_b\"])\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter(mode=\"lines\", name=\"Difference\", x=merge[\"date\"], y=(merge[\"cumavg_a\"] / merge[\"cumavg_b\"] - 1) * 100)\n",
    "])\n",
    "fig.update_layout(title=\"Mean order size: the last lead change was a few days ago\", xaxis_title=\"Date\", yaxis_title=\"Group A % advantage over group B\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much to choose here. Going by this, the test should probably continue to run. It's close, and the line isn't *that* flat, having recently seen a swing of 5.8 percentage points in three days. But again, we have more things to look at.\n",
    "\n",
    "Next \"round\", conversion rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_by_day = orders.groupby([\"date\", \"group\"], as_index=False).agg({\"transaction_id\": \"count\"})\n",
    "ov_by_day = ov_by_day.merge(visits, on=[\"date\", \"group\"], how=\"inner\")\n",
    "ov_by_day = ov_by_day.rename(columns={\"transaction_id\": \"orders\"})\n",
    "ov_by_day[\"conversion\"] = ov_by_day[\"orders\"] / ov_by_day[\"visits\"]\n",
    "\n",
    "ov_by_day[\"orders_cum\"] = ov_by_day.groupby(\"group\")[\"orders\"].cumsum()\n",
    "ov_by_day[\"visits_cum\"] = ov_by_day.groupby(\"group\")[\"visits\"].cumsum()\n",
    "ov_by_day[\"conversion_cum\"] = ov_by_day[\"orders_cum\"] / ov_by_day[\"visits_cum\"]\n",
    "\n",
    "fig = px.line(ov_by_day, x=\"date\", y=\"conversion_cum\", color=\"group\")\n",
    "fig.update_layout(title=\"Group B clearly has higher conversion\", xaxis_title=\"Date\", yaxis_title=\"Running conversion rate\", legend_title_text=\"Group\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much to say; group B is just better. 16% better, to be specific. It did decline a bit here in the last couple weeks, but not nearly by enough to lose the lead.\n",
    "\n",
    "Next I've been asked to make a scatterplot for orders per user. A bar chart would be the most obvious way to do it, but it doesn't matter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitor_groups = pd.DataFrame({\"visitor_id\": orders[\"visitor_id\"], \"group\": orders[\"group\"]})\n",
    "visitor_groups = visitor_groups.drop_duplicates()\n",
    "\n",
    "grouped = orders.groupby(\"visitor_id\", as_index=False).agg({\"transaction_id\": \"count\"})\n",
    "grouped = grouped.merge(visitor_groups, how=\"left\", on=\"visitor_id\")\n",
    "\n",
    "fig = px.scatter(grouped, x=\"visitor_id\", y=\"transaction_id\", color=\"group\")\n",
    "fig.update_layout(title=\"1 is the only normal number of visits for a user\", xaxis_title=\"Visitor ID\", yaxis_title=\"Orders\", legend_traceorder=\"reversed\", legend_title_text=\"Group\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The message is clear: anything that isn't 1 is an outlier. That said, there aren't any massive outliers to throw off simple calculations either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[\"transaction_id\"].describe(percentiles=[.01, .05, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with order size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(orders, x=\"transaction_id\", y=\"revenue\", color=\"group\")\n",
    "fig.update_layout(title=\"Orders get noticeably thin from 60 up\", xaxis_title=\"Transaction ID\", yaxis_title=\"Revenue\", legend_title_text=\"Group\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, not too many of those 300 orders were actually 300, but doing it with the original has the presence of that one 20k order squishing the rest down and making the chart pretty useless. Also, I *really* feel like there should be a bar chart of this, so here it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(orders, x=\"revenue\", nbins=38)\n",
    "fig.update_layout(title=\"The oddly straight slope down to the 70s\", xaxis_title=\"Revenue\", yaxis_title=\"Number of orders\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical significance tests\n",
    "Now we run some actual mathematical tests to see if the differences are that big, as opposed to me looking at pictures and making fleshy judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #just for this one thing near the end\n",
    "# The test we're using is quite robust to outliers (like, it's ranked), so don't need the \"normal orders only\" versions of the tables to have \"normal\" quite as narrow\n",
    "cutoff = np.percentile(orders_orig[\"revenue\"], 95)\n",
    "orders_small = orders_orig[orders_orig[\"revenue\"] <= cutoff]\n",
    "# Not fixing the normal orders only cumulative values, because they won't be needed\n",
    "\n",
    "ovs_by_day = orders_small.groupby([\"date\", \"group\"], as_index=False).agg({\"transaction_id\": \"count\"})\n",
    "ovs_by_day = ovs_by_day.merge(visits, on=[\"date\", \"group\"], how=\"inner\")\n",
    "ovs_by_day = ovs_by_day.rename(columns={\"transaction_id\": \"orders\"})\n",
    "ovs_by_day[\"conversion\"] = ovs_by_day[\"orders\"] / ovs_by_day[\"visits\"]\n",
    "\n",
    "ov_by_day_a = ov_by_day[ov_by_day[\"group\"] == \"A\"]\n",
    "ov_by_day_b = ov_by_day[ov_by_day[\"group\"] == \"B\"]\n",
    "ovs_by_day_a = ovs_by_day[ovs_by_day[\"group\"] == \"A\"]\n",
    "ovs_by_day_b = ovs_by_day[ovs_by_day[\"group\"] == \"B\"]\n",
    "\n",
    "ovd_a_cv = ov_by_day_a[\"conversion\"]\n",
    "ovd_b_cv = ov_by_day_b[\"conversion\"]\n",
    "ovsd_a_cv = ovs_by_day_a[\"conversion\"]\n",
    "ovsd_b_cv = ovs_by_day_b[\"conversion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, the difference in conversion rate, taking all orders into account. To be specific about it, our H<sub>0</sub> is that there's no difference in the conversion rate by day and H<sub>1</sub> is that we do see a difference in conversion rate by day. Specifically what the p-value will be of is that what group B experienced leads to higher conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "results = st.mannwhitneyu(ovd_a_cv, ovd_b_cv, use_continuity=True, alternative=\"less\")\n",
    "print(\"p-value:\", results.pvalue)\n",
    "if results.pvalue < alpha:\n",
    "    print(\"Statistical significance! (If 5% was a good choice of alpha)\")\n",
    "else:\n",
    "    print(\"The null hypothesis remains intact.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7%, nice. Group B's lead in conversion is probably meaningful after all.\n",
    "\n",
    "Next up is a difference in order size, with all orders, and counting them as their actual values instead of capping them. (Not that capping them or not makes much difference since the Mann-Whitney U test is rank-based.) H<sub>0</sub> here is no effect as going by the raw order sizes – what we're testing against each other is just two lists of how much revenue each order was, one list for each group – and H<sub>1</sub> is that the difference between the groups does have an effect on the order size. The p-value is of group A's advantage, or group B's disadvantage if you want to look at it that way. We don't know which is the control group; this is a properly blinded test, after all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = st.mannwhitneyu(orders_orig[orders_orig[\"group\"] == \"A\"][\"revenue\"], orders_orig[orders_orig[\"group\"] == \"B\"][\"revenue\"], use_continuity=True, alternative=\"greater\")\n",
    "print(\"p-value:\", results.pvalue)\n",
    "if results.pvalue < alpha:\n",
    "    print(\"Statistical significance! (If 5% was a good choice of alpha)\")\n",
    "else:\n",
    "    print(\"The null hypothesis remains intact.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No surprise there.\n",
    "\n",
    "The next test is for a difference in conversion, but leaving out the highest 5% of orders by revenue. Like the other conversion rate test, H<sub>0</sub> is no difference between the conversion rates for each day and H<sub>1</sub> is that there is a significant difference. The p-value again refers to group B having higher conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "results = st.mannwhitneyu(ovsd_a_cv, ovsd_b_cv, use_continuity=True, alternative=\"less\")\n",
    "print(\"p-value:\", results.pvalue)\n",
    "if results.pvalue < alpha:\n",
    "    print(\"Statistical significance! (If 5% was a good choice of alpha)\")\n",
    "else:\n",
    "    print(\"The null hypothesis remains intact.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still something to be confident about.\n",
    "\n",
    "The final Mann-Whitney U test we'll be running is for a difference in order size, but only counting the non-big orders, \"non-big\" meaning the same as in the previous test. H<sub>0</sub> is no effect based on the order sizes – again, it's just a list of the orders' revenues – and H<sub>1</sub> is that there is a difference between these by group. Like the other order size test, the p-value is for group A having higher order sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = st.mannwhitneyu(orders_small[orders_small[\"group\"] == \"A\"][\"revenue\"], orders_small[orders_small[\"group\"] == \"B\"][\"revenue\"], use_continuity=True, alternative=\"greater\")\n",
    "print(\"p-value:\", results.pvalue)\n",
    "if results.pvalue < alpha:\n",
    "    print(\"Statistical significance! (If 5% was a good choice of alpha)\")\n",
    "else:\n",
    "    print(\"The null hypothesis remains intact.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *p*-value is *better*, but being better than 43% isn't anything to write home about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever there's a difference that inspires much confidence in itself, it's group B in front, and the differences in those revenue and conversion rate lines are looking pretty stable. I'd be happy to stop the test and declare group B superior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
